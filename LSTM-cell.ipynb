{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from pandas import concat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by activity\n",
    "def data_by_activity(X, y, activities):\n",
    "    # group windows by activity\n",
    "    grouped=list()\n",
    "    #return {a:X[y[:,0]==a] for a in activities}\n",
    "    for i in activities:\n",
    "        ac = X[Y[:,0]==i]\n",
    "        grouped.append(ac)\n",
    "        #print(i,ac.shape)\n",
    "\n",
    "def load_all_data(directory):\n",
    "    # Load\n",
    "    filename=\"mHealth_subject1.csv\"\n",
    "    df = pd.read_csv(directory+filename)\n",
    "    df.insert(0, 'id', 1)\n",
    "\n",
    "\n",
    "    for i in range(9):\n",
    "        number=str(i+2)\n",
    "        filename=\"mHealth_subject\"+number+\".csv\"\n",
    "    #   print(directory+filename)\n",
    "        df_subject = pd.read_csv(directory+filename)\n",
    "        df_subject.insert(0, 'id', i+2)\n",
    "        df = df.append(df_subject)\n",
    "\n",
    "\n",
    "\n",
    "    # Cleaning\n",
    "    df =df.query('label != 0')\n",
    "    raw = df\n",
    "    \n",
    "    # Separate data\n",
    "    X = df.iloc[:, :24]\n",
    "    Y = df.iloc[:,24]\n",
    "\n",
    "    return raw,X,Y\n",
    "\n",
    "\n",
    "def class_breakdown(data):\n",
    "    # convert the numpy array into a dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    # group data by the class value and calculate the number of rows\n",
    "    counts = df.groupby(0).size()\n",
    "    # retrieve raw rows\n",
    "    counts = counts.values\n",
    "    # summarize\n",
    "    for i in range(len(counts)):\n",
    "        percent = counts[i] / len(df) * 100\n",
    "        print('Class=%d, total=%d, percentage=%.3f' % (i + 1, counts[i], percent))\n",
    "\n",
    "\n",
    "# Method to convert data to series\n",
    "def to_series(data, off, activity_list, subject_id):\n",
    "    subject_data = data.query('id==' + str(subject_id))\n",
    "    series = [[]]\n",
    "    for activity in activity_list:\n",
    "        ser = np.asmatrix(subject_data.query(\"label==\"+str(activity)).iloc[:, off]).T\n",
    "        series=np.append(series,ser)\n",
    "    return series\n",
    "\n",
    "\n",
    "def min_max_normalization(X):\n",
    "    row,columns=X.shape\n",
    "    for i in range(columns):\n",
    "        v = X[:, i]  \n",
    "        X[:, i] = (v - v.min()) / ((v.max() - v.min()) if (v.max() - v.min())!=0 else 1)\n",
    "    return X\n",
    "\n",
    "def range_normalization(X,a,b):\n",
    "    row,columns=X.shape\n",
    "    for i in range(columns):\n",
    "        v = X[:, i]  \n",
    "        X[:, i] = (b-a)*((v - v.min()) / ((v.max() - v.min()) if (v.max() - v.min())!=0 else 1))+a\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acc_chest_x</th>\n",
       "      <th>acc_chest_y</th>\n",
       "      <th>acc_chest_z</th>\n",
       "      <th>elect_sig_1</th>\n",
       "      <th>elect_sig_2</th>\n",
       "      <th>acc_left_ank_x</th>\n",
       "      <th>acc_left_ank_y</th>\n",
       "      <th>acc_left_ank_z</th>\n",
       "      <th>gyr_left_ank_x</th>\n",
       "      <th>...</th>\n",
       "      <th>acc_right_arm_x</th>\n",
       "      <th>acc_right_arm_y</th>\n",
       "      <th>acc_right_arm_z</th>\n",
       "      <th>gyr_right_arm_x</th>\n",
       "      <th>gyr_right_arm_y</th>\n",
       "      <th>gyr_right_arm_z</th>\n",
       "      <th>mag_right_arm_x</th>\n",
       "      <th>mag_right_arm_y</th>\n",
       "      <th>mag_right_arm_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.8289</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>2.1010</td>\n",
       "      <td>-0.121400</td>\n",
       "      <td>0.163270</td>\n",
       "      <td>2.4495</td>\n",
       "      <td>-9.7277</td>\n",
       "      <td>-0.493140</td>\n",
       "      <td>-0.25788</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.6442</td>\n",
       "      <td>-9.8757</td>\n",
       "      <td>3.43330</td>\n",
       "      <td>-0.90784</td>\n",
       "      <td>-0.57290</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>-3.3505</td>\n",
       "      <td>-11.89000</td>\n",
       "      <td>5.4671</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.0630</td>\n",
       "      <td>0.141760</td>\n",
       "      <td>2.0233</td>\n",
       "      <td>-0.192570</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>1.7507</td>\n",
       "      <td>-9.7923</td>\n",
       "      <td>-0.024192</td>\n",
       "      <td>-0.25788</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.5060</td>\n",
       "      <td>-9.7488</td>\n",
       "      <td>2.11670</td>\n",
       "      <td>-0.90784</td>\n",
       "      <td>-0.57290</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>1.9181</td>\n",
       "      <td>-5.67690</td>\n",
       "      <td>-3.1540</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.6363</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>1.6945</td>\n",
       "      <td>-0.226060</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>2.4836</td>\n",
       "      <td>-9.4641</td>\n",
       "      <td>0.124550</td>\n",
       "      <td>-0.25788</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.6872</td>\n",
       "      <td>-9.9677</td>\n",
       "      <td>1.23080</td>\n",
       "      <td>-0.90784</td>\n",
       "      <td>-0.57290</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>4.4654</td>\n",
       "      <td>-2.29000</td>\n",
       "      <td>-6.7470</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.5303</td>\n",
       "      <td>0.250110</td>\n",
       "      <td>1.8225</td>\n",
       "      <td>-0.159080</td>\n",
       "      <td>0.129770</td>\n",
       "      <td>2.5743</td>\n",
       "      <td>-9.3353</td>\n",
       "      <td>0.131890</td>\n",
       "      <td>-0.25788</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.6247</td>\n",
       "      <td>-9.7028</td>\n",
       "      <td>0.72319</td>\n",
       "      <td>-0.90784</td>\n",
       "      <td>-0.57290</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>6.4595</td>\n",
       "      <td>-0.37111</td>\n",
       "      <td>-12.5020</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.2791</td>\n",
       "      <td>0.317060</td>\n",
       "      <td>1.4391</td>\n",
       "      <td>-0.037677</td>\n",
       "      <td>0.267920</td>\n",
       "      <td>2.8298</td>\n",
       "      <td>-9.2048</td>\n",
       "      <td>0.307640</td>\n",
       "      <td>-0.28200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.7955</td>\n",
       "      <td>-9.2540</td>\n",
       "      <td>0.59980</td>\n",
       "      <td>-0.91176</td>\n",
       "      <td>-0.58522</td>\n",
       "      <td>0.101290</td>\n",
       "      <td>7.2062</td>\n",
       "      <td>2.48540</td>\n",
       "      <td>-16.4870</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  acc_chest_x  acc_chest_y  acc_chest_z  elect_sig_1  elect_sig_2  \\\n",
       "3530   1      -9.8289     0.537270       2.1010    -0.121400     0.163270   \n",
       "3531   1     -10.0630     0.141760       2.0233    -0.192570     0.100470   \n",
       "3532   1      -9.6363    -0.002198       1.6945    -0.226060     0.020931   \n",
       "3533   1      -9.5303     0.250110       1.8225    -0.159080     0.129770   \n",
       "3534   1      -9.2791     0.317060       1.4391    -0.037677     0.267920   \n",
       "\n",
       "      acc_left_ank_x  acc_left_ank_y  acc_left_ank_z  gyr_left_ank_x  ...  \\\n",
       "3530          2.4495         -9.7277       -0.493140        -0.25788  ...   \n",
       "3531          1.7507         -9.7923       -0.024192        -0.25788  ...   \n",
       "3532          2.4836         -9.4641        0.124550        -0.25788  ...   \n",
       "3533          2.5743         -9.3353        0.131890        -0.25788  ...   \n",
       "3534          2.8298         -9.2048        0.307640        -0.28200  ...   \n",
       "\n",
       "      acc_right_arm_x  acc_right_arm_y  acc_right_arm_z  gyr_right_arm_x  \\\n",
       "3530          -1.6442          -9.8757          3.43330         -0.90784   \n",
       "3531          -2.5060          -9.7488          2.11670         -0.90784   \n",
       "3532          -2.6872          -9.9677          1.23080         -0.90784   \n",
       "3533          -2.6247          -9.7028          0.72319         -0.90784   \n",
       "3534          -2.7955          -9.2540          0.59980         -0.91176   \n",
       "\n",
       "      gyr_right_arm_y  gyr_right_arm_z  mag_right_arm_x  mag_right_arm_y  \\\n",
       "3530         -0.57290         0.084052          -3.3505        -11.89000   \n",
       "3531         -0.57290         0.084052           1.9181         -5.67690   \n",
       "3532         -0.57290         0.084052           4.4654         -2.29000   \n",
       "3533         -0.57290         0.084052           6.4595         -0.37111   \n",
       "3534         -0.58522         0.101290           7.2062          2.48540   \n",
       "\n",
       "      mag_right_arm_z  label  \n",
       "3530           5.4671      8  \n",
       "3531          -3.1540      8  \n",
       "3532          -6.7470      8  \n",
       "3533         -12.5020      8  \n",
       "3534         -16.4870      8  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory=\"Data/MHEALTHDATASET/\"\n",
    "\n",
    "raw,X,y=load_all_data(directory)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acc_chest_x</th>\n",
       "      <th>acc_chest_y</th>\n",
       "      <th>acc_chest_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.8289</td>\n",
       "      <td>0.537270</td>\n",
       "      <td>2.1010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.0630</td>\n",
       "      <td>0.141760</td>\n",
       "      <td>2.0233</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.6363</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>1.6945</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.5303</td>\n",
       "      <td>0.250110</td>\n",
       "      <td>1.8225</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.2791</td>\n",
       "      <td>0.317060</td>\n",
       "      <td>1.4391</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98299</th>\n",
       "      <td>10</td>\n",
       "      <td>-5.3457</td>\n",
       "      <td>4.151600</td>\n",
       "      <td>-6.3632</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98300</th>\n",
       "      <td>10</td>\n",
       "      <td>-4.6643</td>\n",
       "      <td>3.923400</td>\n",
       "      <td>-6.0995</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98301</th>\n",
       "      <td>10</td>\n",
       "      <td>-5.3018</td>\n",
       "      <td>3.978800</td>\n",
       "      <td>-5.1998</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98302</th>\n",
       "      <td>10</td>\n",
       "      <td>-5.7742</td>\n",
       "      <td>1.842100</td>\n",
       "      <td>-5.1395</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98303</th>\n",
       "      <td>10</td>\n",
       "      <td>-6.4927</td>\n",
       "      <td>1.909500</td>\n",
       "      <td>-5.5229</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343195 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  acc_chest_x  acc_chest_y  acc_chest_z  label\n",
       "3530    1      -9.8289     0.537270       2.1010      8\n",
       "3531    1     -10.0630     0.141760       2.0233      8\n",
       "3532    1      -9.6363    -0.002198       1.6945      8\n",
       "3533    1      -9.5303     0.250110       1.8225      8\n",
       "3534    1      -9.2791     0.317060       1.4391      8\n",
       "...    ..          ...          ...          ...    ...\n",
       "98299  10      -5.3457     4.151600      -6.3632      9\n",
       "98300  10      -4.6643     3.923400      -6.0995      9\n",
       "98301  10      -5.3018     3.978800      -5.1998      9\n",
       "98302  10      -5.7742     1.842100      -5.1395      9\n",
       "98303  10      -6.4927     1.909500      -5.5229      9\n",
       "\n",
       "[343195 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to beginning we are only going to use accelerometer\n",
    "valid_activities_set=raw.copy()#raw.query(\"label==1 or label==4\")\n",
    "valid_activities_set.columns\n",
    "\n",
    "# Get only 2 activities and accelerometer data\n",
    "data=valid_activities_set[['id','acc_chest_x'    , 'acc_chest_y'    , 'acc_chest_z',\n",
    "                               'acc_left_ank_x' , 'acc_left_ank_y' , 'acc_left_ank_z',\n",
    "                               'acc_right_arm_x', 'acc_right_arm_y', 'acc_right_arm_z','label']].copy()\n",
    "\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample rate is 0.02 seconds, so we are going to make a row with 1152 features of accelerometer \n",
    "# to train the network which means 2.56 s of sampling\n",
    "\n",
    "subjects=data[\"id\"].unique()\n",
    "activities=data[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.7430</td>\n",
       "      <td>0.281030</td>\n",
       "      <td>-4.5326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.3634</td>\n",
       "      <td>-0.514450</td>\n",
       "      <td>-3.3726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.2686</td>\n",
       "      <td>0.299820</td>\n",
       "      <td>1.1533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.8007</td>\n",
       "      <td>-0.367020</td>\n",
       "      <td>-1.4015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.1906</td>\n",
       "      <td>-0.064572</td>\n",
       "      <td>-4.7637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1       2    3    4    5    6    7    8    9    ...  376  377  \\\n",
       "0 -7.7430  0.281030 -4.5326  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1 -9.3634 -0.514450 -3.3726  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2 -9.2686  0.299820  1.1533  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3 -7.8007 -0.367020 -1.4015  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4 -8.1906 -0.064572 -4.7637  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "   378  379  380  381  382  383  384  385  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  8.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  8.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  1.0  8.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  1.0  8.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  1.0  8.0  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_row=128\n",
    "sensor_cols = 9 # cause we are using accelerometer only\n",
    "features=(samples_by_row*sensor_cols)+2 # +2 cause id and act\n",
    "\n",
    "time_series_data=np.zeros((1,features))\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    for act in activities:\n",
    "        subject_data=data.query(\"label==\"+str(act)+\" and id==\"+str(subject))\n",
    "        np_subject_data=subject_data.values\n",
    "        new_row=np.zeros((samples_by_row,sensor_cols))\n",
    "        count=0\n",
    "        temp_count=0\n",
    "        \n",
    "        for s_data in np_subject_data:\n",
    "            new_row[temp_count]=s_data[1:sensor_cols+1]\n",
    "            \n",
    "            if (count+1) % samples_by_row == 0 and count != 0:\n",
    "                definitive_row = np.append(new_row.flatten(), [subject,act])\n",
    "                temp_count = 0\n",
    "                time_series_data = np.append(time_series_data, np.asmatrix(definitive_row) , axis=0)\n",
    "            \n",
    "            count=count+1\n",
    "            \n",
    "time_series_data = np.delete(time_series_data, 0, 0)            \n",
    "df_time_series_data = pd.DataFrame(data=time_series_data)\n",
    "\n",
    "df_time_series_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2670, 386)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2670, 383)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data\n",
    "\n",
    "X = df_time_series_data.iloc[:, 0:383]\n",
    "Y = df_time_series_data.iloc[:,385]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data in train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=10)\n",
    "X_train=np.asmatrix(X_train)\n",
    "Y_train=np.asmatrix(Y_train).T\n",
    "\n",
    "X_test=X_test.reset_index()\n",
    "Y_test=Y_test.reset_index()\n",
    "X_test = X_test.astype(np.float)\n",
    "Y_test = Y_test.astype(np.float)\n",
    "\n",
    "X_test = np.asmatrix(X_test.drop(columns=\"index\"))\n",
    "Y_test = np.asmatrix(Y_test.drop(columns=\"index\"))\n",
    "\n",
    "# normalize\n",
    "X_train=range_normalization(X_train,-1,1)\n",
    "#Y_train=range_normalization(Y_train)\n",
    "X_test=range_normalization(X_test,-1,1)\n",
    "\n",
    "\n",
    "df_x_train = pd.DataFrame(data=X_train)\n",
    "df_x_train.head()\n",
    "\n",
    "df_y_train = pd.DataFrame(data=Y_train)\n",
    "df_y_train.head()\n",
    "\n",
    "df_x_train.to_csv(r'x_train_set.csv', index = False)\n",
    "df_y_train.to_csv(r'y_train_set.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002, 383)\n",
      "(2002, 1)\n",
      "(668, 383)\n",
      "(668, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "# X_train=range_normalization(X_train,-1,1)\n",
    "# Y_train=range_normalization(Y_train,0,1)\n",
    "# X_test=range_normalization(X_test,-1,1)\n",
    "# Y_test=range_normalization(Y_test,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for Keras test\n",
    "# Sequence\n",
    "def split_data_for_keras(X_data, z_dim,x_dim,y_dim):\n",
    "    data_sequence = np.zeros((z_dim,x_dim,y_dim))\n",
    "\n",
    "    count_rows=0\n",
    "    count_columns=0\n",
    "    count_z=0\n",
    "\n",
    "    temp_matrix=np.zeros((x_dim,y_dim))\n",
    "\n",
    "    for x in X_data:\n",
    "        data_row,data_col=x.shape\n",
    "        \n",
    "        x_temp = np.squeeze(np.asarray(x))\n",
    "\n",
    "        for x_i in x_temp:\n",
    "            temp_matrix[count_rows][count_columns] = x_i\n",
    "            if count_columns%y_dim==0:\n",
    "                count_columns=0\n",
    "                count_rows += 0\n",
    "            else:\n",
    "                count_columns+=1\n",
    "        data_sequence[count_z] = temp_matrix\n",
    "        count_z+=1\n",
    "\n",
    "    return data_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "enc = enc.fit(Y_train)\n",
    "\n",
    "y_input = enc.transform(Y_train)\n",
    "\n",
    "y_input_test = enc.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=128\n",
    "n_features=3\n",
    "\n",
    "# Train\n",
    "x_input = split_data_for_keras(X_train, Y_train.shape[0],n_steps,n_features)\n",
    "\n",
    "\n",
    "#Test\n",
    "x_input_test = split_data_for_keras(X_test, Y_test.shape[0],n_steps,n_features)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "\n",
    "    Bidirectional(\n",
    "    LSTM(\n",
    "          units=50,\n",
    "          input_shape=[x_input.shape[1], x_input.shape[2]]\n",
    "      )\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(y_input.shape[1], activation='softmax'))\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer bidirectional_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 2.4774 - acc: 0.0861 - val_loss: 2.4795 - val_acc: 0.0896\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 2.4632 - acc: 0.0916 - val_loss: 2.4765 - val_acc: 0.0896\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4651 - acc: 0.0905 - val_loss: 2.4723 - val_acc: 0.0896\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4608 - acc: 0.1027 - val_loss: 2.4748 - val_acc: 0.0896\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4617 - acc: 0.0955 - val_loss: 2.4722 - val_acc: 0.0896\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4622 - acc: 0.0888 - val_loss: 2.4726 - val_acc: 0.0896\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 2.4629 - acc: 0.0905 - val_loss: 2.4727 - val_acc: 0.0896\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 2.4614 - acc: 0.0916 - val_loss: 2.4732 - val_acc: 0.0896\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4600 - acc: 0.0933 - val_loss: 2.4731 - val_acc: 0.0896\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4606 - acc: 0.1016 - val_loss: 2.4734 - val_acc: 0.0896\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4610 - acc: 0.0883 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 2.4607 - acc: 0.0833 - val_loss: 2.4735 - val_acc: 0.0896\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4604 - acc: 0.0866 - val_loss: 2.4739 - val_acc: 0.0896\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4619 - acc: 0.0927 - val_loss: 2.4738 - val_acc: 0.0896\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4601 - acc: 0.0922 - val_loss: 2.4729 - val_acc: 0.0896\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4615 - acc: 0.0922 - val_loss: 2.4726 - val_acc: 0.0896\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4595 - acc: 0.1016 - val_loss: 2.4737 - val_acc: 0.0896\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4610 - acc: 0.0966 - val_loss: 2.4741 - val_acc: 0.0896\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4611 - acc: 0.0861 - val_loss: 2.4738 - val_acc: 0.0896\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4598 - acc: 0.0994 - val_loss: 2.4743 - val_acc: 0.0896\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4605 - acc: 0.0877 - val_loss: 2.4744 - val_acc: 0.0896\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4608 - acc: 0.0949 - val_loss: 2.4733 - val_acc: 0.0896\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4598 - acc: 0.0877 - val_loss: 2.4732 - val_acc: 0.0896\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4599 - acc: 0.1022 - val_loss: 2.4748 - val_acc: 0.0896\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4621 - acc: 0.0927 - val_loss: 2.4723 - val_acc: 0.0896\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4621 - acc: 0.0866 - val_loss: 2.4727 - val_acc: 0.0896\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 2.4607 - acc: 0.0938 - val_loss: 2.4730 - val_acc: 0.0896\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4614 - acc: 0.0972 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4613 - acc: 0.0949 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4597 - acc: 0.0983 - val_loss: 2.4738 - val_acc: 0.0896\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4603 - acc: 0.0961 - val_loss: 2.4737 - val_acc: 0.0896\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4603 - acc: 0.0916 - val_loss: 2.4735 - val_acc: 0.0896\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4604 - acc: 0.1077 - val_loss: 2.4731 - val_acc: 0.0896\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 2.4591 - acc: 0.0961 - val_loss: 2.4733 - val_acc: 0.0896\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 2.4605 - acc: 0.0944 - val_loss: 2.4725 - val_acc: 0.0896\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 2.4606 - acc: 0.0972 - val_loss: 2.4729 - val_acc: 0.0896\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 2.4602 - acc: 0.1022 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 2.4599 - acc: 0.0872 - val_loss: 2.4735 - val_acc: 0.0896\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 4s 153ms/step - loss: 2.4606 - acc: 0.1022 - val_loss: 2.4738 - val_acc: 0.0896\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 2.4600 - acc: 0.0983 - val_loss: 2.4745 - val_acc: 0.0896\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 2.4602 - acc: 0.1049 - val_loss: 2.4738 - val_acc: 0.0896\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 2s 52ms/step - loss: 2.4603 - acc: 0.0999 - val_loss: 2.4737 - val_acc: 0.0896\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 2.4601 - acc: 0.0944 - val_loss: 2.4734 - val_acc: 0.0896\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 2.4618 - acc: 0.0994 - val_loss: 2.4733 - val_acc: 0.0896\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 2.4596 - acc: 0.0966 - val_loss: 2.4735 - val_acc: 0.0896\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 2.4609 - acc: 0.0983 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 2.4607 - acc: 0.1011 - val_loss: 2.4736 - val_acc: 0.0896\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 2.4603 - acc: 0.0983 - val_loss: 2.4734 - val_acc: 0.0896\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 2.4604 - acc: 0.0900 - val_loss: 2.4733 - val_acc: 0.0896\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 2.4602 - acc: 0.1049 - val_loss: 2.4739 - val_acc: 0.0896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "\n",
    "    x_input, y_input,\n",
    "\n",
    "    epochs=50,\n",
    "\n",
    "    batch_size = 64,\n",
    "\n",
    "    validation_split=0.1,\n",
    "\n",
    "    shuffle=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 12ms/step - loss: 2.4650 - acc: 0.0614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.465009927749634, 0.06137724593281746]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_input_test, y_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 128, 3)\n",
      "(85504, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_input_test.shape)\n",
    "\n",
    "nuemat=(x_input_test.transpose(2,0,1).reshape(3,-1)).T\n",
    "print(nuemat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.091896</td>\n",
       "      <td>0.096347</td>\n",
       "      <td>0.080154</td>\n",
       "      <td>0.082764</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.086092</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.032061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "1    0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "2    0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "3    0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "4    0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "663  0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "664  0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "665  0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "666  0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "667  0.088992  0.084802  0.091896  0.096347  0.080154  0.082764  0.088571   \n",
       "\n",
       "            7         8         9       10        11  \n",
       "0    0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "1    0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "2    0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "3    0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "4    0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "..        ...       ...       ...      ...       ...  \n",
       "663  0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "664  0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "665  0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "666  0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "667  0.082302  0.098439  0.086092  0.08758  0.032061  \n",
       "\n",
       "[668 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
